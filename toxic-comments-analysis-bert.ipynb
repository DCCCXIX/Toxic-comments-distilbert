{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"id":"iPGUH-Dh7CcQ"},"cell_type":"code","source":"#libs import\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport warnings\nimport re\nwarnings.filterwarnings('ignore')\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"id":"z0vZCUG27CcV"},"cell_type":"code","source":"data = pd.read_csv(r'../input/jigsaw-toxic-comment-classification-challenge/train.csv.zip')\n#test_labels = pd.read_csv(r'/kaggle/input/jigsaw-toxic-comment-classification-challenge/test_labels.csv.zip')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"3nSn1RPQ7CcZ"},"cell_type":"code","source":"#data = data.sample(frac=1).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"Zi73k3Hc7Ccc"},"cell_type":"code","source":"# data_targets = data.drop('id', axis = 1).drop('comment_text', axis = 1)\n# for target in data_targets:\n#     print(data[target].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"id":"qOwYdkRy7Ccf"},"cell_type":"markdown","source":"The dataset is highly unbalanced.\nNow we want to see if one comment can belong to more than one class."},{"metadata":{"trusted":true,"id":"CBDAHKMH7Ccg"},"cell_type":"code","source":"# data.corr().style.background_gradient(cmap='coolwarm', low=0.15)","execution_count":null,"outputs":[]},{"metadata":{"id":"ZON77CNT7Cci"},"cell_type":"markdown","source":"We see that all the classes overlap more or less. the biggest overlaps are between \"insult\" and \"obscene\", \"toxic\" and \"obscene\", \"toxic\" and \"insult\". Threat has the least correlation to other features. Probably people tend to threaten each other in a very polite way. So it's a multiclass classification task with some of the classes overlapping."},{"metadata":{"trusted":true,"id":"q8nQ9xrx7Ccj"},"cell_type":"code","source":"# import seaborn as sns\n\n# multitagging = data_targets.sum(axis = 1).value_counts()\n# sns.barplot(multitagging.index, multitagging.values, alpha=0.8,color='green')","execution_count":null,"outputs":[]},{"metadata":{"id":"kYA0LG9b7Ccl"},"cell_type":"markdown","source":"Most comments are clean, and the maximum amount of tags for one post is 6. So it's possible for one post to be in all of the groups at the same time. But those are a minority, plus we must take into consideration the fact that the data gathered is flawed because it was based on human reports."},{"metadata":{"id":"90HNCQvx7Ccm"},"cell_type":"markdown","source":"Now to get some features we'll look at the average character count, word count and punctuation for every type of comment, take a look at the most frequently used words by comment type, and engineer some n-grams."},{"metadata":{"trusted":true,"id":"YvhRcq0O7Ccn"},"cell_type":"code","source":"# toxic_comments = data[data['toxic'] == 1]\n# severe_toxic_comments = data[data['severe_toxic'] == 1]\n# obscene_comments = data[data['obscene'] == 1]\n# threat_comments = data[data['threat'] == 1]\n# insult_comments = data[data['insult'] == 1]\n# identity_hate_comments = data[data['identity_hate'] == 1]\n\n# clean_comments = data[(data['toxic'] == 0) &\n#                                 (data['severe_toxic'] == 0) &\n#                                 (data['obscene'] == 0) &\n#                                 (data['threat'] == 0) &\n#                                 (data['insult'] == 0) &\n#                                 (data['identity_hate'] == 0)]\n\n# comment_types = [toxic_comments, severe_toxic_comments, obscene_comments, threat_comments, insult_comments, identity_hate_comments, clean_comments]\n# comment_types_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate', 'clean']\n# print()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"mKUxLw3k7Ccq"},"cell_type":"code","source":"# lengthByCommentType = []\n\n# length_index = 0\n# for comment_type in comment_types:\n#     print\n#     lengthByCommentType.append(comment_type['comment_text'].str.len().mean())        \n\n# print(lengthByCommentType)\n# plt.plot(lengthByCommentType)\n# #commentLengths.sort()\n# #plt.plot(commentLengths)","execution_count":null,"outputs":[]},{"metadata":{"id":"lNTKhhun7Ccs"},"cell_type":"markdown","source":"As we see, total length of the comment can probably be a useful feature as the meanletter counts differ alot. Toxic comments on average have much lower letter count than clean ones, but especially passionate shitshtorms exceed even clean comments in their letter counts. However, comment lengths themselves are not balanced at all, with some extremely short and extremely long ones in every group."},{"metadata":{"trusted":true,"id":"i7tlPZGb7Cct"},"cell_type":"code","source":"# import collections\n# from heapq import nlargest\n\n# i = 0\n# for comment_type in comment_types:\n#     amountByCommentType = {}\n#     print(\"Dictionary for \" + comment_types_names[i] + \":\")\n#     i += 1\n    \n#     for comment in comment_type:\n#         commentString = comment_type['comment_text']\n#         commentString_text = commentString.str.split()        \n#         for stringArray in commentString_text:\n#             #commentLengths.append(len(stringArray))\n#             for word in stringArray:\n#                 if word in amountByCommentType:\n#                     amountByCommentType[word] += 1\n#                 else:\n#                     amountByCommentType[word] = 1\n#     TwentyHighest = nlargest(20, amountByCommentType, key = amountByCommentType.get) \n#     for val in TwentyHighest: \n#         print(val, \":\", amountByCommentType.get(val)) \n                \n#     #amountByCommentType.append(i/len(comment_type))\n    \n# #print(amountByCommentType)\n# #plt.plot(amountByCommentType)","execution_count":null,"outputs":[]},{"metadata":{"id":"5tUM5g087Ccw"},"cell_type":"markdown","source":"Now we preprocess the data. Stipping all the comments off html tags, punctuation and then stemming the words"},{"metadata":{"trusted":true,"id":"VACJX60X7Ccx"},"cell_type":"code","source":"def count_regex(regexp = \"\", comment = None):    \n    return len(re.findall(regexp, comment))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"F0aB6G1R7Cc0"},"cell_type":"code","source":"#creating new columns of features for the dataset\ndef PrepareText(data):\n    #Comment's total length\n    data['total_length_count'] = data['comment_text'].apply(len)\n    #Amount of symbols\n    data['symbols_count'] = data['comment_text'].apply(lambda comment: sum(comment.count(w) for w in '*&$%'))\n    #Exclamation mark count\n    data['exclamation_count'] = data['comment_text'].apply(lambda comment: comment.count('!')) \n    #Question mark count\n    data['question_count'] = data['comment_text'].apply(lambda comment: comment.count('?'))\n    #Punctuation count\n    data['punctuation_count'] = data['comment_text'].apply(lambda comment: sum(comment.count(w) for w in '.,;:'))\n    #Amount of upper case letters\n    data['uppercase_amount'] = data['comment_text'].apply(lambda comment: sum(1 for c in comment if c.isupper()))\n    #Amount of upper case letters compared to the text's length\n    data['FULLCAPS_COUNT'] = data['uppercase_amount']/data['total_length_count']\n    #Amount of unique words compared to total word count\n    data['total_unique_words_count'] = data['comment_text'].apply(lambda comment: len(set(w for w in comment.split())))\n    #Amount of \". [upper_case_letter]\" constructions\n    data['polite_sentence_count'] = data['comment_text'].apply(lambda comment: sum(comment.count(w) for w in '\\.\\s[A-Z]'))\n    #Amount of f??k\n    data['fuck_count'] = data['comment_text'].apply(lambda comment: count_regex(r'[Ff]\\S{2}[Kk]', comment))\n    #Amount of 'you'\n    data['you_count'] = data['comment_text'].str.lower().apply(lambda comment: count_regex(r'you', comment) + count_regex(r' u ', comment))\n    #Amount of 'we' and 'I'\n    data['wei_count'] = data['comment_text'].str.lower().apply(lambda comment: comment.count(' we ') + comment.count(' i ')) \n\n    #Amount of racial slurs and the like\n    racial_slurs = ['gyp', 'slav', 'jew', 'yid', 'kike',  'goy', 'gentile',\n        'skinhead', 'anti', 'na+zi', 'kurd', 'turk', 'nationalis',\n        r'fa+t', r'whi+te', 'cracker', 'racis', r'spi+c', r'beane+r',\n        r'coo+n', 'fasc', 'homo', 'negr', 'akba+r', r'alla+h', r'chi+nk',\n        r'goo+k', 'nigg', r'kaf+', 'kebab', r'ni+p', 'islam', 'muslim',\n        'raghead', 'towelhead']\n\n    for slur in racial_slurs:\n        if 'racial_slur_count' in data.columns:\n            data['racial_slur_count'] = data['racial_slur_count'] + data['comment_text'].str.lower().apply(lambda comment: count_regex(slur, comment))\n        else:\n            data['racial_slur_count'] = 0         \n            data['racial_slur_count'] = data['comment_text'].str.lower().apply(lambda comment: count_regex(slur, comment))\n    \n    #Amout of slurs by gender or sexual orientation\n    LGBT_slurs = [r'ga+y', r'f[a-z]gg[a-z]t', r'fa+g', 'trans', 'lgbt', 'bugg',\n                            'fudgep', 'siss', 'marimach', 'nancy', 'batty',\n                            'twink', 'dyke', 'lesb', 'trann', 'shemal', 'quean', 'breeder']\n    \n    for slur in LGBT_slurs:\n        if 'LGBT_slur_count' not in data.columns:\n            data['LGBT_slur_count'] = 0\n            data['LGBT_slur_count'] = data['comment_text'].str.lower().apply(lambda comment: count_regex(slur, comment))\n        else:    \n            data['LGBT_slur_count'] = data['LGBT_slur_count'] + data['comment_text'].str.lower().apply(lambda comment: count_regex(slur, comment))                                                                          \n                                                  \n    #Amount of possibly obscene words\n    obscene_words = ['sex', 'whore', 'shit', 'piss', 'bastard', 'rape', 'sodom', 'cock', 'dick']  \n\n    for word in obscene_words:\n        if 'obscene_word_count' not in data.columns:\n            data['obscene_word_count'] = 0\n            data['obscene_word_count'] = data['comment_text'].str.lower().apply(lambda comment: count_regex(slur, comment))\n        else:\n            data['obscene_word_count'] = data['obscene_word_count'] + data['comment_text'].str.lower().apply(lambda comment: count_regex(slur, comment))\n                                                                   \n    #Amount of threatening words\n    threat_words = ['kill', 'murder', 'hate', 'die']\n                                                                             \n    for word in threat_words:\n        if 'threat_words_count' not in data.columns:\n            data['threat_words_count'] = 0\n            data['threat_words_countt'] = data['comment_text'].str.lower().apply(lambda comment: count_regex(slur, comment))\n        else:\n            data['threat_words_count'] = data['threat_words_count'] + data['comment_text'].str.lower().apply(lambda comment: count_regex(slur, comment))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"Qm3m5YyP7Cc2"},"cell_type":"code","source":"PrepareText(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"7rYUR-f27Cc5"},"cell_type":"code","source":"feature_columns = ['comment_text', 'total_length_count', 'symbols_count', 'exclamation_count',\n                   'question_count', 'punctuation_count', 'uppercase_amount', 'FULLCAPS_COUNT',\n                   'total_unique_words_count', 'polite_sentence_count', 'fuck_count', 'you_count',\n                   'wei_count', 'racial_slur_count', 'LGBT_slur_count', 'obscene_word_count', 'threat_words_count']\n\nnumerical_features = ['total_length_count', 'symbols_count', 'exclamation_count',\n                   'question_count', 'punctuation_count', 'uppercase_amount', 'FULLCAPS_COUNT',\n                   'total_unique_words_count', 'polite_sentence_count', 'fuck_count', 'you_count',\n                   'wei_count', 'racial_slur_count', 'LGBT_slur_count', 'obscene_word_count', 'threat_words_count']\n\nclass_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"lxGaYjAm7Cc7"},"cell_type":"code","source":"def clean_text(comment):    \n    comment = re.sub(r\" yourselfgo \", \" yourself go \", comment)\n    comment = re.sub(r\" fucksex \", \" fuck sex \", comment)\n    comment = re.sub(r\" u \", \" you \", comment)\n    comment = re.sub(r\"what's\", \"what is \", comment)\n    comment = re.sub(r\"\\'s\", \" \", comment)\n    comment = re.sub(r\"\\'ve\", \" have \", comment)\n    comment = re.sub(r\"can't\", \"can not \", comment)\n    comment = re.sub(r\"n't\", \" not \", comment)\n    comment = re.sub(r\"i'm\", \"i am \", comment)\n    comment = re.sub(r\"\\'re\", \" are \", comment)\n    comment = re.sub(r\"\\'d\", \" would \", comment)\n    comment = re.sub(r\"\\'ll\", \" will \", comment)\n    comment = re.sub(r\"\\'scuse\", \" excuse \", comment)\n    comment = re.sub('\\W', ' ', comment)\n    comment = re.sub('\\s+', ' ', comment)\n    comment_clean = comment.strip(' ')\n    return comment_clean\n\ndef cleanHtml(comment):\n    cleanr = re.compile('<.*?>')\n    no_html = re.sub(cleanr, ' ', str(comment))\n    return no_html\n\ndef cleanPunc(comment):\n    no_punctuation = re.sub(r'[?|!|\\'|\"|#]',r'',comment)\n    no_punctuation = re.sub(r'[.|,|)|(|\\|/]',r' ',comment)\n    no_punctuation= no_punctuation.strip()\n    no_punctuation = no_punctuation.replace(\"\\n\",\" \")\n    return no_punctuation\n\ndef keepAlpha(comment):\n    alpha_sent = \"\"\n    for word in comment.split():\n        alpha_word = re.sub('[^a-z A-Z]+', ' ', word)\n        alpha_sent += alpha_word\n        alpha_sent += \" \"\n    alpha_sent = alpha_sent.strip()\n    return alpha_sent\n\ndata['comment_text'] = data['comment_text'].str.lower()\ndata['comment_text'] = data['comment_text'].apply(clean_text)\ndata['comment_text'] = data['comment_text'].apply(cleanHtml)\ndata['comment_text'] = data['comment_text'].apply(cleanPunc)\ndata['comment_text'] = data['comment_text'].apply(keepAlpha)","execution_count":null,"outputs":[]},{"metadata":{"id":"yZJUQCwy-Seb","outputId":"ed988f60-fd46-4aea-be3d-34eac0300670","trusted":true},"cell_type":"code","source":"!pip install transformers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"U6lhgqAY7CdO"},"cell_type":"code","source":"import torch\nimport transformers as ppb\nconfig_class, model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertConfig, ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"pLfURBDB7CdQ","outputId":"ac1d3c9c-bd85-4a1c-8fe6-1d434337645b"},"cell_type":"code","source":"if torch.cuda.is_available():      \n    device = torch.device(\"cuda\")\n    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n    print('We will use the GPU:', torch.cuda.get_device_name(0))\nelse:\n    print('No GPU available, using the CPU instead.')\n    device = torch.device(\"cpu\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"glqZ-Qd07CdT","outputId":"d2e963a3-8ed3-4c20-f811-7fcdaa98324a"},"cell_type":"code","source":"print('Initializing tokenizer')\ntokenizer = tokenizer_class.from_pretrained(pretrained_weights)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"-ybkHExx7CdW"},"cell_type":"code","source":"comments = data.comment_text.values\nlabels_l = data[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].values.astype(float)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"QR8T31iK7CdY"},"cell_type":"code","source":"def encode(comments):\n    print('Encoding comments')\n    input_ids_l = []\n    attention_masks_l = []\n    for comment in comments:  \n        encoded_dict = tokenizer.encode_plus(\n                            comment,\n                            add_special_tokens = True,\n                            max_length = 512,\n                            pad_to_max_length = True,\n                            return_attention_mask = True,\n                            return_tensors = 'pt',\n                       )     \n        input_ids_l.append(encoded_dict['input_ids'])    \n        attention_masks_l.append(encoded_dict['attention_mask'])        \n    return input_ids_l, attention_masks_l\n\ndef data_preparation(input_ids_l, attention_masks_l):\n    print('Data preparation')\n    with torch.cuda.device(0):\n        input_ids = torch.cat(input_ids_l, dim=0).to(device='cuda')\n        attention_masks = torch.cat(attention_masks_l, dim=0).to(device='cuda')\n        labels = torch.tensor(labels_l).to(device='cuda')\n    return input_ids, attention_masks\n\ndef get_lhs(input_ids, attention_masks, model):\n    print('Getting last hidden states')\n    last_hidden_states_l = []\n    j = 0\n    for item in range(500000):\n        if len(input_ids)-(j+50) < 0:\n            break\n        print('j = ' + str(j))\n        if len(input_ids)-(j+50) > 50:\n            print('Calculating samples: ' + str(j) + ' - ' + str(j+49))\n            input_id = input_ids[j:j+50,:]        \n            attention_mask = attention_masks[j:j+50,:]\n            j+=50\n        else:                    \n            print('Calculating last samples')\n            input_id = input_ids[j:,:]    \n            attention_mask = attention_masks[j:,:]\n            j+=50\n        with torch.no_grad():\n            last_hidden_states = model(input_id, attention_mask=attention_mask)\n            \n        #last_hidden_states_l.append(last_hidden_states[0][:,0,:].cpu().numpy())\n        #last_hidden_states_l.append(hidden_states[2][:,-2].cpu().numpy())\n        \n        last_hidden_states_l.append(last_hidden_states.cpu().numpy())\n    return last_hidden_states_l","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"xmVz0Cgh7Cdb","outputId":"1b13f475-6ed4-4ee4-c81c-347ef664012f"},"cell_type":"code","source":"input_ids_l, attention_masks_l = encode(comments)\ninput_ids, attention_masks = data_preparation(input_ids_l, attention_masks_l)\nlabels = torch.from_numpy(labels_l)","execution_count":null,"outputs":[]},{"metadata":{"id":"YQZy75X_Upw-","trusted":true},"cell_type":"code","source":"# from torch.utils.data import TensorDataset, random_split\n\n# dataset = TensorDataset(input_ids, attention_masks, labels)\n\n# train_size = int(0.9 * len(dataset))\n# valid_size = len(dataset) - train_size\n\n# train_dataset, valid_dataset = random_split(dataset, [train_size, valid_size])\n\n# print('{:>5,} training samples'.format(train_size))\n# print('{:>5,} validation samples'.format(valid_size))","execution_count":null,"outputs":[]},{"metadata":{"id":"ZnBaIXzFFfwh","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_valid, y_train, y_valid = train_test_split(input_ids, labels_l, test_size=0.1, random_state=1488)","execution_count":null,"outputs":[]},{"metadata":{"id":"LdQhGBXCERpq","trusted":true},"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\nclass text_dataset(Dataset):\n    def __init__(self,x,y, transform=None):\n        self.x = x\n        self.y = y\n        self.transform = transform\n        \n    def __getitem__(self,index):\n        ids_review = self.x[index]\n        hcc = self.y[index] # toxic comment        \n        list_of_labels = [torch.from_numpy(hcc)] \n        return ids_review, list_of_labels[0]\n\n    def __len__(self):\n        return len(self.x)","execution_count":null,"outputs":[]},{"metadata":{"id":"FmOoLeLvFqOO","trusted":true},"cell_type":"code","source":"training_dataset = text_dataset(X_train,y_train)\nvalid_dataset = text_dataset(X_valid,y_valid)\n\nbatch_size = 16\n\ndataloaders_dict = {'train': DataLoader(training_dataset, batch_size=batch_size, shuffle=False),\n                   'val': DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n                   }\ndataset_sizes = {'train':len(X_train),\n                'val':len(X_valid)}","execution_count":null,"outputs":[]},{"metadata":{"id":"4EX3tKQXMPh9","outputId":"83a0288a-7962-4a2a-c982-929a01a9943a","trusted":true},"cell_type":"code","source":"import torch.nn as nn\nclass DistilBertClassifier(torch.nn.Module):\n   def __init__(self, config):\n        super().__init__()\n        self.distilbert = model_class.from_pretrained(pretrained_weights)\n        self.num_labels = config.num_labels        \n        self.pre_classifier = nn.Linear(config.hidden_size, config.hidden_size)\n        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n        self.dropout = nn.Dropout(config.seq_classif_dropout)\n        self.output_hidden_states = config.output_hidden_states\n\n        nn.init.xavier_normal_(self.classifier.weight)\n\n   def forward(self, input_ids=None, attention_mask=None, labels=None):\n      distilbert_output = self.distilbert(input_ids=input_ids, attention_mask=attention_mask)\n      hidden_state = distilbert_output[0]\n      pooled_output = hidden_state[:, 0]\n      pooled_output = self.pre_classifier(pooled_output)\n      pooled_output = nn.ReLU()(pooled_output)\n      pooled_output = self.dropout(pooled_output)\n      logits = self.classifier(pooled_output)\n      return logits\n\nprint('Initializing model')\nconfig = config_class(vocab_size_or_config_json_file=32000, dropout=0.1, num_labels=6, intermediate_size=3072)\nmodel = DistilBertClassifier(config)\nmodel.cuda()","execution_count":null,"outputs":[]},{"metadata":{"id":"oBiOa-EpVPUT","trusted":true},"cell_type":"code","source":"# from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n# batch_size = 16\n\n# train_dataloader = DataLoader(\n#             train_dataset,\n#             sampler = RandomSampler(train_dataset),\n#             batch_size = batch_size\n#         )\n\n# valid_dataloader = DataLoader(\n#             valid_dataset,\n#             sampler = SequentialSampler(valid_dataset),\n#             batch_size = batch_size\n#         )\n","execution_count":null,"outputs":[]},{"metadata":{"id":"tg-Tszd9Rx8R","trusted":true},"cell_type":"code","source":"from transformers import AdamW\nfrom torch.optim import lr_scheduler\n\nepochs = 3\nlrlast = .001\nlrmain = 3e-5\n\noptimizer_ft = AdamW(model.parameters(),\n                  lr = 5e-5,\n                  eps = 1e-8\n                  )\n\ncriterion = nn.BCEWithLogitsLoss()\n\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=3, gamma=0.1)","execution_count":null,"outputs":[]},{"metadata":{"id":"oxU6bXZ8WPcx","trusted":true},"cell_type":"code","source":"def accuracy_thresh(y_pred, y_true, thresh:float=0.4, sigmoid:bool=True):    \n    if sigmoid: y_pred = y_pred.sigmoid()\n    return np.mean(((y_pred>thresh).float()==y_true.float()).float().cpu().numpy(), axis=1).sum()","execution_count":null,"outputs":[]},{"metadata":{"id":"9AfzFPN9V16h","trusted":true},"cell_type":"code","source":"import time\nimport datetime","execution_count":null,"outputs":[]},{"metadata":{"id":"-_nP0pFA8-5O","outputId":"5108532c-9d5f-48aa-e23c-6762528c74fc","trusted":true},"cell_type":"code","source":"import gc\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"id":"5ZdjQJZcRXUY","outputId":"cd57bfd6-1d46-4999-e002-7c8f3d29f949","trusted":true},"cell_type":"code","source":"import copy\ndef train_model(model, criterion, optimizer, scheduler, num_epochs=2):\n    model.train()\n    since = time.time()\n    print('starting')\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_loss = 100\n\n    for epoch in range(num_epochs):\n        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n        print('-' * 10)\n        \n        for phase in ['train', 'val']:\n            if phase == 'train':\n                scheduler.step()\n                model.train()\n            else:\n                model.eval()\n\n            running_loss = 0.0            \n            beta_score_accuracy = 0.0            \n            micro_roc_auc_acc = 0.0\n                       \n            for inputs, hcc in dataloaders_dict[phase]:\n                \n                inputs = inputs.to(device) \n                hcc = hcc.to(device)            \n                optimizer.zero_grad()\n                \n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)                    \n                    loss = criterion(outputs,hcc.float())\n                    \n                    if phase == 'train':                        \n                        loss.backward()\n                        optimizer.step()\n\n                running_loss += loss.item() * inputs.size(0)\n                \n                micro_roc_auc_acc +=  accuracy_thresh(outputs.view(-1,6),hcc.view(-1,6))\n                \n            epoch_loss = running_loss / dataset_sizes[phase]\n\n            \n            epoch_micro_roc_acc = micro_roc_auc_acc / dataset_sizes[phase]\n\n            print('{} total loss: {:.4f} '.format(phase,epoch_loss ))\n            print('{} micro_roc_auc_acc: {:.4f}'.format( phase, epoch_micro_roc_acc))\n\n            if phase == 'val' and epoch_loss < best_loss:\n                print('saving with loss of {}'.format(epoch_loss),\n                      'improved over previous {}'.format(best_loss))\n                best_loss = epoch_loss\n                best_model_wts = copy.deepcopy(model.state_dict())\n                torch.save(model.state_dict(), 'distilbert_model_weights.pth')\n         \n\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed // 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(float(best_loss)))\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model\n \nprint('done')","execution_count":null,"outputs":[]},{"metadata":{"id":"_lXgsnhpRnWA","outputId":"d69ea539-26a1-4ac5-fe20-5128c55fe3e3","trusted":true},"cell_type":"code","source":"model_ft1 = train_model(model, criterion, optimizer_ft, exp_lr_scheduler,num_epochs=2)","execution_count":null,"outputs":[]},{"metadata":{"id":"Ruj5iAa8SHKp","outputId":"0f3b4a41-1133-4701-97ff-87bc4cd271c9","trusted":true},"cell_type":"code","source":"last_hidden_states_l = get_lhs(input_ids, attention_masks, model_ft1111)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"tWoSTXPj7Cde"},"cell_type":"code","source":"features = np.concatenate(last_hidden_states_l)\nlabels_lgbm = data[class_names]\nfeatures_r = np.append(features, data[numerical_features].to_numpy(), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"x68h5Vkf7Cdu"},"cell_type":"code","source":"import lightgbm\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import cross_val_score, train_test_split\n\ndef Classification(xtrainlgbmc, ytrainlgbmc, params):\n    model_dict = {}\n                  \n    for target in class_names:    \n        print('Predicting {0} comments:'.format(target))\n        \n        train_matrix, valid_matrix, y_train, y_valid = train_test_split(xtrainlgbmc, ytrainlgbmc, test_size = 0.1, random_state = 42)        \n        d_train = lightgbm.Dataset(train_matrix, label = y_train[target])\n        d_valid = lightgbm.Dataset(valid_matrix, label = y_valid[target])\n        valid = [d_train, d_valid]\n    \n        lgbmc = lightgbm.train(params = params, train_set = d_train, valid_sets = valid, verbose_eval = 10, num_boost_round = 10000, early_stopping_rounds = 150)\n                \n        #y_predlgbmc = lgbmc.predict(xtestlgbmc)\n        y_predlgbmc_train = lgbmc.predict(xtrainlgbmc)\n        print('Roc_auc for training set is: %.4f' % roc_auc_score(ytrainlgbmc[target], y_predlgbmc_train))        \n        #submission[target] = y_predlgbmc\n        model_dict[target] = lgbmc\n\n    return model_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"0t5hxTZZ7Cdw"},"cell_type":"code","source":"LGBMparameters = {\n                  'learning_rate': 0.05,\n                  'application': 'binary',                  \n                  'max_depth' : 6,\n                  'num_leaves' : 15,\n                  'verbosity': -1,\n                  'n_thread' : 2,\n                  'metric': 'auc',                  \n                  'lambda_l1': 5,\n                  'lambda_l2': 5\n                 }\n\nmodellos = Classification(features_r, labels_lgbm, LGBMparameters)","execution_count":null,"outputs":[]},{"metadata":{"id":"0UACLGNioWPP","outputId":"7b1abc2f-9567-4253-c2c9-70e3e132ee3c","trusted":true},"cell_type":"code","source":"print(modellos)","execution_count":null,"outputs":[]},{"metadata":{"id":"ikvq5VNOm8m6","trusted":true},"cell_type":"code","source":"for name, model in modellos.items():\n  model.save_model('model{0}.txt'.format(name))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"hLjjMaPR7Cdg"},"cell_type":"code","source":"test_data = pd.read_csv(r'../input/jigsaw-toxic-comment-classification-challenge/test.csv.zip')\ntest_comments = test_data.comment_text.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"Xp3Frda-7Cdj"},"cell_type":"code","source":"PrepareText(test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"0jzeXbKW7Cdl"},"cell_type":"code","source":"test_data['comment_text'] = test_data['comment_text'].str.lower()\ntest_data['comment_text'] = test_data['comment_text'].apply(clean_text)\ntest_data['comment_text'] = test_data['comment_text'].apply(cleanHtml)\ntest_data['comment_text'] = test_data['comment_text'].apply(cleanPunc)\ntest_data['comment_text'] = test_data['comment_text'].apply(keepAlpha)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"2fmoVS3z7Cdn","outputId":"4c9978f9-82b1-4bb1-be50-92468bfbcc1a"},"cell_type":"code","source":"test_input_ids_l, test_attention_masks_l = encode(test_comments)\ntest_input_ids, test_attention_masks = data_preparation(test_input_ids_l, test_attention_masks_l)\n#test_last_hidden_states_l = get_lhs(test_input_ids, test_attention_masks, model_ft1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_lhs_dbert(input_ids, attention_masks, model):\n    print('Getting last hidden states')\n    last_hidden_states_l = []\n    j = 0\n    for item in range(500000):\n        if len(input_ids)-(j+5) < 0:\n            break\n        print('j = ' + str(j))\n        if len(input_ids)-(j+5) > 10:\n            print('Calculating samples: ' + str(j) + ' - ' + str(j+4))\n            input_id = input_ids[j:j+5,:]        \n            attention_mask = attention_masks[j:j+5,:]\n            j+=5\n        else:                    \n            print('Calculating last samples')\n            input_id = input_ids[j:,:]    \n            attention_mask = attention_masks[j:,:]\n            j+=5\n        with torch.no_grad():\n            last_hidden_states = model(input_id, attention_mask=attention_mask)            \n            \n        last_hidden_states_l.append(last_hidden_states[0][:,0,:].cpu().numpy())\n        #last_hidden_states_l.append(hidden_states[2][:,-2].cpu().numpy())      \n        \n    return last_hidden_states_l","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del model\ngc.collect","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lhs_distilbert = get_lhs_dbert(test_input_ids, test_attention_masks, model_ft1.distilbert)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.cuda.empty_cache()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import gc\ngc.collect","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"ubDUMRo97Cdp"},"cell_type":"code","source":"test_features = np.concatenate(test_last_hidden_states_l)\ntest_features_r = np.append(test_features, test_data[numerical_features].to_numpy(), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"LPenNtUp7Cds"},"cell_type":"code","source":"submission = pd.DataFrame.from_dict({'id': test_data['id']})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"lyNLiIsr7Cd0","outputId":"9ce01e89-4945-49af-eeda-f598e497a124"},"cell_type":"code","source":"for target in class_names:    \n        print('Predicting {0} comments:'.format(target))\n        modello = modellos[target]\n        y_predlgbmc = modello.predict(test_features_r)                 \n        submission[target] = y_predlgbmc","execution_count":null,"outputs":[]},{"metadata":{"id":"uHbvTjCS23vt","outputId":"10086648-e4fe-4ed1-ffeb-ef387476f33f","trusted":true},"cell_type":"code","source":"print(submission)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"uPMkHs4Q7Cd2"},"cell_type":"code","source":"submission.to_csv('lgb_bert_submission1.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Источники:\n* https://mccormickml.com/2019/07/22/BERT-fine-tuning/#33-tokenize-dataset\n* https://arxiv.org/abs/1706.03762\n* https://medium.com/@armandj.olivares/using-bert-for-classifying-documents-with-long-texts-5c3e7b04573d\n* http://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/\n* ноутбуки по той же задаче\n\n(ГПУ отлетело в момент предыдущего ковыряния бука, потому возможны косяки при получении last hidden states)"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}